model_config: !!python/object:analysis.base.ModelConfig
  dim_feedforward: 1024
  dropout_rate: 0.0
  embedding_dim: 256
  init_scale: 0.03
  layer_norm: false
  model_type: transformer
  nhead: 4
  num_layers: 3
  scaled_attention: false
  seq_length: 1164
  skip_connections: false
train_config: !!python/object:analysis.base.TrainConfig
  batch_size: 64
  data_dir: !!python/object/apply:pathlib.PosixPath
  - /
  - data
  - datasets
  gradient_clip_val: 0
  learning_rate: 0.001
  lr_schedule: false
  max_epochs: 80
  modal_detach: true
  name_prefix: xformer_rep_00
  num_workers: 1
  optimizer: adamw
  patience: 200
  phenotypes:
  - 23C
  - 25C
  - 27C
  - 30C
  - 33C
  - 35C
  - 37C
  - cu
  - suloc
  - ynb
  - eth
  - gu
  - li
  - mann
  - mol
  - raff
  - sds
  - 4NQO
  save_dir: !!python/object/apply:pathlib.PosixPath
  - /
  - data
  - models
  - transformer
  seed: null
  synthetic_data: false
  use_cache: true
  use_modal: true
  weight_decay: 0.0
